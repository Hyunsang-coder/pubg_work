from __future__ import annotations
import os, time, json, io, uuid, hashlib, html
from datetime import datetime
import streamlit as st
from dotenv import load_dotenv
import sys
try:
    import pandas as pd
except ImportError:
    pd = None

# Ensure project root is on sys.path for Streamlit Cloud
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)
# Also add parent dir as fallback for environments like Streamlit Cloud
PARENT_DIR = os.path.dirname(ROOT_DIR)
if PARENT_DIR not in sys.path:
    sys.path.insert(0, PARENT_DIR)
from src.pptx2md.extract import extract_pptx_to_docs
from src.pptx2md.markdown import docs_to_markdown
from src.pptx2md.options import ExtractOptions
from src.pptx2md.translate import translate_markdown, TranslationConfig
from src.pptx2md.ppt_generator import create_translated_presentation_v2

# ìš©ì–´ì§‘ íŒŒì¼ ì œí•œ ì„¤ì •
MAX_GLOSSARY_ENTRIES = 500  # ìµœëŒ€ ìš©ì–´ ê°œìˆ˜
MAX_FILE_SIZE_MB = 5        # ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB)
MAX_TERM_LENGTH = 100       # ê°œë³„ ìš©ì–´ ìµœëŒ€ ê¸¸ì´
TMP_DIR = os.path.join(ROOT_DIR, "tmp")
os.makedirs(TMP_DIR, exist_ok=True)

def _load_glossary_from_bytes(file_name: str, file_bytes: bytes) -> dict | None:
    """ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš©ì–´ì§‘ì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
    if not file_bytes:
        st.warning("ìš©ì–´ì§‘ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None

    file_size_mb = len(file_bytes) / (1024 * 1024)
    if file_size_mb > MAX_FILE_SIZE_MB:
        st.error(f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ {MAX_FILE_SIZE_MB}MBê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤. (í˜„ì¬: {file_size_mb:.1f}MB)")
        return None

    file_extension = file_name.lower().split('.')[-1]

    if file_extension == 'json':
        try:
            text = file_bytes.decode('utf-8')
        except UnicodeDecodeError as e:
            st.error(f"JSON íŒŒì¼ì„ UTF-8ë¡œ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
            return None
        try:
            glossary = json.loads(text)
            if not isinstance(glossary, dict):
                st.error("JSON íŒŒì¼ì€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.")
                return None
            return _validate_glossary(glossary)
        except json.JSONDecodeError as e:
            st.error(f"JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}")
            return None

    elif file_extension in ['xlsx', 'xls']:
        if pd is None:
            st.error("ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ pandasê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None
        try:
            df = pd.read_excel(io.BytesIO(file_bytes))
        except Exception as e:
            st.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            return None

        if len(df.columns) < 2:
            st.error("ì—‘ì…€ íŒŒì¼ì€ ìµœì†Œ 2ê°œì˜ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì›ë¬¸, ë²ˆì—­)")
            return None

        if len(df) > MAX_GLOSSARY_ENTRIES:
            st.error(f"ìš©ì–´ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ìµœëŒ€ {MAX_GLOSSARY_ENTRIES}ê°œê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤. (í˜„ì¬: {len(df)}ê°œ)")
            return None

        glossary = {}
        skipped_rows = 0

        for idx, row in df.iterrows():
            source = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
            target = str(row.iloc[1]).strip() if pd.notna(row.iloc[1]) else ""

            if not source or not target:
                skipped_rows += 1
                continue

            if len(source) > MAX_TERM_LENGTH or len(target) > MAX_TERM_LENGTH:
                st.warning(f"í–‰ {idx + 2}: ìš©ì–´ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ {MAX_TERM_LENGTH}ì). ê±´ë„ˆëœë‹ˆë‹¤.")
                skipped_rows += 1
                continue

            glossary[source] = target

        if skipped_rows > 0:
            st.info(f"{skipped_rows}ê°œ í–‰ì´ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤ (ë¹ˆ ê°’ ë˜ëŠ” ë„ˆë¬´ ê¸´ ìš©ì–´)")

        return _validate_glossary(glossary)

    else:
        st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. JSON ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None


def load_glossary_from_file(uploaded_file) -> dict:
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ìš©ì–´ì§‘ì„ ë¡œë“œí•©ë‹ˆë‹¤. JSONê³¼ ì—‘ì…€ íŒŒì¼ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤."""
    if uploaded_file is None:
        return None
    file_bytes = uploaded_file.getvalue()
    return _load_glossary_from_bytes(uploaded_file.name, file_bytes)

def _validate_glossary(glossary: dict) -> dict:
    """ìš©ì–´ì§‘ ìµœì¢… ê²€ì¦"""
    if not glossary:
        st.warning("ìš©ì–´ì§‘ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return None
    
    if len(glossary) > MAX_GLOSSARY_ENTRIES:
        st.error(f"ìš©ì–´ ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ìµœëŒ€ {MAX_GLOSSARY_ENTRIES}ê°œê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤.")
        return None
    
    # ì¤‘ë³µ ì œê±° ë° í†µê³„
    original_count = len(glossary)
    glossary = {k.strip(): v.strip() for k, v in glossary.items() if k.strip() and v.strip()}
    
    if len(glossary) != original_count:
        st.info(f"ì¤‘ë³µ ë˜ëŠ” ë¹ˆ í•­ëª© ì œê±°ë¨: {original_count} â†’ {len(glossary)}ê°œ")
    
    return glossary


def get_glossary_from_upload(uploaded_file):
    """ì—…ë¡œë“œëœ ìš©ì–´ì§‘ì„ ìºì‹±í•˜ê³  ì¬ì‚¬ìš©í•©ë‹ˆë‹¤."""
    if uploaded_file is None:
        st.session_state.pop("cached_glossary", None)
        st.session_state.pop("cached_glossary_meta", None)
        return None

    file_bytes = uploaded_file.getvalue()
    file_hash = hashlib.md5(file_bytes).hexdigest()
    meta = {
        "name": uploaded_file.name,
        "hash": file_hash,
        "size": len(file_bytes),
    }

    if st.session_state.get("cached_glossary_meta") == meta:
        return st.session_state.get("cached_glossary")

    glossary = _load_glossary_from_bytes(uploaded_file.name, file_bytes)
    if glossary:
        st.session_state["cached_glossary"] = glossary
        st.session_state["cached_glossary_meta"] = meta
    else:
        st.session_state.pop("cached_glossary", None)
        st.session_state.pop("cached_glossary_meta", None)
    return glossary

load_dotenv()
st.set_page_config(page_title="PPT ë²ˆì—­ ì†”ë£¨ì…˜", layout="centered")

# í—¤ë” ë¡œê³ : íŒŒì¼ì´ ì¡´ì¬í•  ë•Œë§Œ í‘œì‹œí•´ ë ˆì´ì•„ì›ƒì„ ê¹¨ëœ¨ë¦¬ì§€ ì•ŠëŠ”ë‹¤
logo_path = os.path.join(ROOT_DIR, "assets", "ppt_logo.png")
header_cols = st.columns([1, 8]) if os.path.exists(logo_path) else None

if header_cols:
    with header_cols[0]:
        st.image(logo_path, width=80)
    with header_cols[1]:
        st.title("PPT ë²ˆì—­ ì†”ë£¨ì…˜")
else:
    st.title("PPT ë²ˆì—­ ì†”ë£¨ì…˜")

if "translation_logs" not in st.session_state:
    st.session_state.translation_logs = []
if "log_placeholder" not in st.session_state:
    st.session_state.log_placeholder = None


def _render_logs():
    placeholder = st.session_state.get("log_placeholder")
    if placeholder is None:
        return

    if st.session_state.translation_logs:
        content = "<br/>".join(html.escape(msg) for msg in st.session_state.translation_logs)
        html_block = (
            "<div style='max-height:320px; overflow-y:auto; background-color:#0f1116; "
            "padding:12px; border-radius:8px; font-family:monospace; font-size:13px;'>"
            f"{content}</div>"
        )
        placeholder.markdown(html_block, unsafe_allow_html=True)
    else:
        placeholder.markdown("_ì§„í–‰ ë¡œê·¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤._")


def append_log(message: str):
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.translation_logs.append(f"[{timestamp}] {message}")
    _render_logs()


def reset_logs():
    st.session_state.translation_logs = []
    _render_logs()

with st.sidebar:
    st.header("ê¸°ëŠ¥ ì„ íƒ")
    
    # í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜ ë²„íŠ¼
    current_page = st.session_state.get("current_page", "extract")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“„ í…ìŠ¤íŠ¸ ì¶”ì¶œ", use_container_width=True, type="primary" if current_page == "extract" else "secondary"):
            st.session_state.current_page = "extract"
            st.rerun()
    
    with col2:
        if st.button("ğŸŒ PPT ë²ˆì—­", use_container_width=True, type="primary" if current_page == "translate" else "secondary"):
            st.session_state.current_page = "translate"
            st.rerun()
    
    st.divider()
    
    # í˜„ì¬ í˜ì´ì§€ì— ë”°ë¥¸ ì˜µì…˜ í‘œì‹œ
    if current_page == "extract":
        st.subheader("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜µì…˜")
        with_notes = st.checkbox("ë°œí‘œì ë…¸íŠ¸ í¬í•¨", value=False)
        # UIì—ì„œëŠ” í•œêµ­ì–´ë¡œ í‘œì‹œí•˜ë˜ ì‹¤ì œ ê°’ì€ ì˜ì–´ë¡œ ë§¤í•‘
        figures_display = st.selectbox("ê·¸ë¦¼ ì²˜ë¦¬", ["í”Œë ˆì´ìŠ¤í™€ë”", "ìƒëµ"], index=0)
        figures_map = {"í”Œë ˆì´ìŠ¤í™€ë”": "placeholder", "ìƒëµ": "omit"}
        figures = figures_map[figures_display]
        
        charts_display = st.selectbox("ì°¨íŠ¸ ì²˜ë¦¬", ["ë ˆì´ë¸”", "í”Œë ˆì´ìŠ¤í™€ë”", "ìƒëµ"], index=0)
        charts_map = {"ë ˆì´ë¸”": "labels", "í”Œë ˆì´ìŠ¤í™€ë”": "placeholder", "ìƒëµ": "omit"}
        charts = charts_map[charts_display]
        
        # ê¸°ë³¸ê°’ ì„¤ì • (ë²ˆì—­ í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•  ë•Œ)
        model = "gpt-4o-mini"
        default_prompt = """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ë²ˆì—­ì‚¬ì…ë‹ˆë‹¤. PPT ë²ˆì—­ ì‹œ:
- ì›ë¬¸ ì˜ë¯¸ ìœ ì§€í•˜ë˜ ê°„ê²°í•˜ê²Œ ë²ˆì—­
- ë²ˆì—­ë¬¸ì´ ì›ë¬¸ë³´ë‹¤ 20% ì´ìƒ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ì œí•œ
- ìì—°ìŠ¤ëŸ½ê³  ë¹„ì¦ˆë‹ˆìŠ¤ì— ì í•©í•œ í‘œí˜„ ì‚¬ìš©"""
        extra_prompt = default_prompt
        glossary_file = None
        
    elif current_page == "translate":
        st.subheader("ë²ˆì—­ ì˜µì…˜")
        model = st.selectbox("OpenAI ëª¨ë¸", ["gpt-5", "gpt-4.1", "gpt-4.1-mini", "gpt-4o-mini", "gpt-5-nano"], index=3)
        default_prompt = """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ë²ˆì—­ì‚¬ì…ë‹ˆë‹¤. PPT ë²ˆì—­ ì‹œ:
- ì›ë¬¸ ì˜ë¯¸ ìœ ì§€í•˜ë˜ ê°„ê²°í•˜ê²Œ ë²ˆì—­
- ë²ˆì—­ë¬¸ì´ ì›ë¬¸ë³´ë‹¤ 20% ì´ìƒ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ì œí•œ
- ìì—°ìŠ¤ëŸ½ê³  ë¹„ì¦ˆë‹ˆìŠ¤ì— ì í•©í•œ í‘œí˜„ ì‚¬ìš©"""
        
        extra_prompt = st.text_area("ë²ˆì—­ í”„ë¡¬í”„íŠ¸", value=default_prompt, height=150, placeholder="í†¤, ìŠ¤íƒ€ì¼, ìš©ì–´ ê·œì¹™ ë“±...")
        
        # ìš©ì–´ì§‘ íŒŒì¼ ì—…ë¡œë” - JSONê³¼ ì—‘ì…€ ëª¨ë‘ ì§€ì›
        glossary_file = st.file_uploader(
            "ìš©ì–´ì§‘ íŒŒì¼", 
            type=["json", "xlsx", "xls"],
            help="JSON íŒŒì¼ ë˜ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. ì—‘ì…€ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì›ë¬¸, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì€ ë²ˆì—­ì–´ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.",
            key="glossary_upload"
        )
        
        # ìš©ì–´ì§‘ íŒŒì¼ ì œí•œì‚¬í•­ ì•ˆë‚´ (compact)
        st.markdown(f"""
        **ìš©ì–´ì§‘ íŒŒì¼ ì œí•œì‚¬í•­:**  
        â€¢ ìµœëŒ€ íŒŒì¼ í¬ê¸°: {MAX_FILE_SIZE_MB}MB  
        â€¢ ìµœëŒ€ ìš©ì–´ ê°œìˆ˜: {MAX_GLOSSARY_ENTRIES}ê°œ  
        â€¢ ê°œë³„ ìš©ì–´ ìµœëŒ€ ê¸¸ì´: {MAX_TERM_LENGTH}ì
        """, unsafe_allow_html=True)
        
        # ìš©ì–´ì§‘ ë¯¸ë¦¬ë³´ê¸°
        if glossary_file:
            glossary_preview = get_glossary_from_upload(glossary_file)
            if glossary_preview:
                st.success(f"âœ… ìš©ì–´ì§‘ ë¡œë“œ ì™„ë£Œ: {len(glossary_preview)}ê°œ í•­ëª©")
                
                with st.expander("ìš©ì–´ì§‘ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    preview_items = list(glossary_preview.items())[:10]  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                    for source, target in preview_items:
                        st.write(f"â€¢ `{source}` â†’ `{target}`")
                    if len(glossary_preview) > 10:
                        st.write(f"... ì™¸ {len(glossary_preview) - 10}ê°œ í•­ëª©")
        else:
            get_glossary_from_upload(None)
            
        # ê¸°ë³¸ê°’ ì„¤ì • (í…ìŠ¤íŠ¸ ì¶”ì¶œ í˜ì´ì§€ì—ì„œ ì‚¬ìš©í•  ë•Œ)
        with_notes = False
        figures = "placeholder"
        charts = "labels"

for k in ["uploaded_path", "docs", "markdown", "translated_md", "show_translation_tab", "output_pptx_path", "output_pptx_name"]:
    if k not in st.session_state:
        st.session_state[k] = None

if "last_action" not in st.session_state:
    st.session_state.last_action = None

if "current_page" not in st.session_state:
    st.session_state.current_page = "extract"


def run_action(action_type: str):
    """ê³µí†µ ì•¡ì…˜ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        if action_type == "translate_markdown":
            reset_logs()
            append_log("Markdown ë²ˆì—­ ì¤€ë¹„ ì¤‘...")
            glossary = get_glossary_from_upload(glossary_file) if glossary_file else st.session_state.get("cached_glossary")
            if glossary:
                append_log(f"ìš©ì–´ì§‘ ì ìš©: {len(glossary)}ê°œ í•­ëª©")
            cfg = TranslationConfig(target_lang="en", glossary=glossary, extra_instructions=extra_prompt, model=model)

            start = time.time()
            append_log(f"Markdown ë²ˆì—­ ìš”ì²­ ì „ì†¡ â€” ê¸€ì ìˆ˜ {len(st.session_state.markdown or ''):,}ì")
            with st.spinner("ë²ˆì—­ ì¤‘..."):
                st.session_state.translated_md = translate_markdown(st.session_state.markdown, cfg)
                st.session_state.show_translation_tab = True
            elapsed = int(time.time() - start)
            append_log(f"Markdown ë²ˆì—­ ì™„ë£Œ ({elapsed//60}ë¶„ {elapsed%60}ì´ˆ)")
            st.info(f"ë²ˆì—­ ì†Œìš” ì‹œê°„: {elapsed//60}ë¶„ {elapsed%60}ì´ˆ")
            st.session_state.last_action = "translate_markdown"
            st.rerun()

        elif action_type == "translate_ppt":
            reset_logs()
            append_log("PPT ë²ˆì—­ ì¤€ë¹„ ì¤‘...")
            glossary = get_glossary_from_upload(glossary_file) if glossary_file else st.session_state.get("cached_glossary")
            if glossary:
                append_log(f"ìš©ì–´ì§‘ ì ìš©: {len(glossary)}ê°œ í•­ëª©")
            cfg = TranslationConfig(target_lang="en", glossary=glossary, extra_instructions=extra_prompt, model=model)

            base_name = os.path.splitext(st.session_state.get("uploaded_original_name") or os.path.basename(st.session_state.uploaded_path))[0]
            output_pptx = os.path.abspath(f"{base_name}_translated.pptx")
            if st.session_state.output_pptx_path and os.path.exists(st.session_state.output_pptx_path):
                try:
                    os.remove(st.session_state.output_pptx_path)
                except OSError:
                    pass

            start = time.time()
            slide_count = len(st.session_state.docs) if st.session_state.docs else "?"
            append_log(f"PPT ë²ˆì—­ ë° ìƒì„± ì‹œì‘ â€” ëŒ€ìƒ ìŠ¬ë¼ì´ë“œ {slide_count}")
            with st.spinner("PPT ë²ˆì—­ ë° ìƒì„± ì¤‘..."):
                create_translated_presentation_v2(
                    st.session_state.uploaded_path,
                    output_pptx,
                    cfg,
                    progress_callback=append_log,
                )
            elapsed = int(time.time() - start)
            st.success(f"PPT ìƒì„± ì™„ë£Œ! ì†Œìš” ì‹œê°„: {elapsed//60}ë¶„ {elapsed%60}ì´ˆ")
            append_log(f"PPT ë²ˆì—­ ì™„ë£Œ ({elapsed//60}ë¶„ {elapsed%60}ì´ˆ)")

            st.session_state.output_pptx_path = output_pptx
            st.session_state.output_pptx_name = f"{base_name}_translated.pptx"
            st.session_state.last_action = "translate_ppt"
            st.rerun()

    except Exception as e:
        append_log(f"ì˜¤ë¥˜: {str(e)}")
        st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# í˜„ì¬ í˜ì´ì§€ì— ë”°ë¥¸ ë©”ì¸ ì»¨í…ì¸  í‘œì‹œ
current_page = st.session_state.get("current_page", "extract")

if current_page == "extract":
    st.header("ğŸ“„ PPT í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    st.write("PPT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , í•„ìš”ì‹œ ë²ˆì—­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    uploaded = st.file_uploader("PPTX íŒŒì¼ ì—…ë¡œë“œ", type=["pptx"], key="extract_uploader") 
    if uploaded:
        file_bytes = uploaded.getvalue()
        file_hash = hashlib.md5(file_bytes).hexdigest()
        meta = {
            "name": uploaded.name,
            "hash": file_hash,
            "size": len(file_bytes),
        }

        if st.session_state.get("uploaded_file_meta") != meta:
            if st.session_state.uploaded_path and os.path.exists(st.session_state.uploaded_path):
                try:
                    os.remove(st.session_state.uploaded_path)
                except OSError:
                    pass

            tmp_filename = f"{uuid.uuid4().hex}_{uploaded.name}"
            tmp_path = os.path.join(TMP_DIR, tmp_filename)
            with open(tmp_path, "wb") as f:
                f.write(file_bytes)

            st.session_state.uploaded_path = tmp_path
            st.session_state.uploaded_original_name = uploaded.name
            st.session_state.docs = None
            st.session_state.markdown = None
            st.session_state.translated_md = None
            st.session_state.output_pptx_path = None
            st.session_state.output_pptx_name = None
            st.session_state.uploaded_file_meta = meta
            reset_logs()

    col1, col2 = st.columns(2)
    with col1:
        if st.button("Markdown ë³€í™˜", use_container_width=True, disabled=not st.session_state.uploaded_path):
            reset_logs()
            append_log("ìŠ¬ë¼ì´ë“œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘")
            opts = ExtractOptions(with_notes=with_notes, figures=figures, charts=charts)
            docs = extract_pptx_to_docs(st.session_state.uploaded_path, opts)
            st.session_state.docs = docs
            st.session_state.markdown = docs_to_markdown(docs, opts)
            append_log(f"Markdown ìƒì„± ì™„ë£Œ â€” ìŠ¬ë¼ì´ë“œ {len(docs)}ê°œ")

    with col2:
        if st.button("ë²ˆì—­ (Markdown)", use_container_width=True, disabled=not st.session_state.markdown):
            run_action("translate_markdown")

elif current_page == "translate":
    st.header("ğŸŒ ë²ˆì—­ëœ PPT ìƒì„±")
    st.write("ì›ë³¸ PPT íŒŒì¼ì˜ ë””ìì¸ì„ ìœ ì§€í•˜ë©´ì„œ ë‚´ë¶€ í…ìŠ¤íŠ¸ë§Œ ë²ˆì—­ëœ ìƒˆë¡œìš´ PPT íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    
    uploaded = st.file_uploader("PPTX íŒŒì¼ ì—…ë¡œë“œ", type=["pptx"], key="translate_uploader") 
    if uploaded:
        file_bytes = uploaded.getvalue()
        file_hash = hashlib.md5(file_bytes).hexdigest()
        meta = {
            "name": uploaded.name,
            "hash": file_hash,
            "size": len(file_bytes),
        }

        if st.session_state.get("uploaded_file_meta") != meta:
            if st.session_state.uploaded_path and os.path.exists(st.session_state.uploaded_path):
                try:
                    os.remove(st.session_state.uploaded_path)
                except OSError:
                    pass

            tmp_filename = f"{uuid.uuid4().hex}_{uploaded.name}"
            tmp_path = os.path.join(TMP_DIR, tmp_filename)
            with open(tmp_path, "wb") as f:
                f.write(file_bytes)

            st.session_state.uploaded_path = tmp_path
            st.session_state.uploaded_original_name = uploaded.name
            st.session_state.docs = None
            st.session_state.markdown = None
            st.session_state.translated_md = None
            st.session_state.output_pptx_path = None
            st.session_state.output_pptx_name = None
            st.session_state.uploaded_file_meta = meta
            reset_logs()

    if st.button("ë²ˆì—­ëœ PPT ìƒì„±", use_container_width=True, disabled=not st.session_state.uploaded_path):
        run_action("translate_ppt")

# í˜ì´ì§€ë³„ ê²°ê³¼ í‘œì‹œ
if current_page == "extract":
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ í˜ì´ì§€ì˜ ë¯¸ë¦¬ë³´ê¸°
    if st.session_state.markdown:
        st.divider()
        # Auto-switch to translation tab if translation exists
        default_tab = 1 if st.session_state.translated_md else 0
        tab1, tab2 = st.tabs(["Markdown ë¯¸ë¦¬ë³´ê¸°", "ë²ˆì—­ë³¸ ë¯¸ë¦¬ë³´ê¸°"])
        
        with tab1:
            st.code(st.session_state.markdown, language="markdown", height=400)
            st.download_button("Markdown ë‹¤ìš´ë¡œë“œ", st.session_state.markdown.encode("utf-8"), 
                              os.path.splitext(os.path.basename(st.session_state.uploaded_path))[0] + ".md")
        
        with tab2:
            if st.session_state.translated_md:
                st.code(st.session_state.translated_md, language="markdown", height=400)
            else:
                st.info("ë²ˆì—­ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

elif current_page == "translate":
    # PPT ë²ˆì—­ í˜ì´ì§€ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if st.session_state.output_pptx_path and os.path.exists(st.session_state.output_pptx_path):
        st.divider()
        with open(st.session_state.output_pptx_path, "rb") as f:
            st.download_button(
                "ë²ˆì—­ëœ PPT ë‹¤ìš´ë¡œë“œ",
                data=f.read(),
                file_name=st.session_state.output_pptx_name or os.path.basename(st.session_state.output_pptx_path),
                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
            )

# ê³µí†µ ì§„í–‰ ë¡œê·¸ (ëª¨ë“  í˜ì´ì§€ì—ì„œ í‘œì‹œ)
st.divider()
with st.container():
    st.subheader("ì§„í–‰ ë¡œê·¸")
    st.caption("ë¡œê·¸ê°€ ê¸¸ì–´ì§€ë©´ ìŠ¤í¬ë¡¤í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.")
    st.session_state.log_placeholder = st.empty()
    _render_logs()
